{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6165b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class SimpleDetector(nn.Module):\n",
    "    def __init__(self, num_classes=7, max_objects=7):\n",
    "        super(SimpleDetector, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.max_objects = max_objects\n",
    "\n",
    "        # Use a pre-trained ResNet18 as the feature extractor\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1]  # Remove the last classification layer\n",
    "        self.feature_extractor = nn.Sequential(*modules)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self.max_objects * (4 + self.num_classes))  # [B, 7 * (4+7)] = [B, 77]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(batch_size, self.max_objects, 4 + self.num_classes)  # [B, 7, 11]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "446dfdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Converts [x_min, y_min, x_max, y_max] â†’ [x_center, y_center, width, height] (normalized)\n",
    "def convert_bbox(x_min, y_min, x_max, y_max, img_width, img_height):\n",
    "    x_center = (x_min + x_max) / 2 / img_width\n",
    "    y_center = (y_min + y_max) / 2 / img_height\n",
    "    width = (x_max - x_min) / img_width\n",
    "    height = (y_max - y_min) / img_height\n",
    "    return [x_center, y_center, width, height]\n",
    "\n",
    "class CollegeFacilitiesDataset(Dataset):\n",
    "    def __init__(self, annotations_file, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load annotations\n",
    "        with open(annotations_file, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "\n",
    "        # Extract unique class labels dynamically\n",
    "        all_classes = set()\n",
    "        for item in self.annotations:\n",
    "            for obj in item['objects']:\n",
    "                all_classes.add(obj['class_label'])\n",
    "        \n",
    "        self.classes = sorted(list(all_classes))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        print(f\"Detected classes: {self.classes}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.annotations[idx]\n",
    "        img_path = os.path.join(self.image_dir, record['filename'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        img_width, img_height = image.size\n",
    "\n",
    "        bboxes = []\n",
    "        class_ids = []\n",
    "\n",
    "        for obj in record['objects']:\n",
    "            bbox = obj['bounding_box']\n",
    "            bbox_norm = convert_bbox(\n",
    "                bbox['x_min'], bbox['y_min'], bbox['x_max'], bbox['y_max'], img_width, img_height\n",
    "            )\n",
    "            bboxes.append(bbox_norm)\n",
    "            class_ids.append(self.class_to_idx[obj['class_label']])\n",
    "\n",
    "        bboxes = torch.tensor(bboxes, dtype=torch.float32)\n",
    "        class_ids = torch.tensor(class_ids, dtype=torch.int64)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, bboxes, class_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8295c91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected classes: ['vase with flowers']\n",
      "Epoch 1 | Loss: 4.4904\n",
      "Epoch 2 | Loss: 4.1011\n",
      "Epoch 3 | Loss: 3.7320\n",
      "Epoch 4 | Loss: 3.2816\n",
      "Epoch 5 | Loss: 2.7164\n",
      "Epoch 6 | Loss: 2.0891\n",
      "Epoch 7 | Loss: 1.4637\n",
      "Epoch 8 | Loss: 0.9080\n",
      "Epoch 9 | Loss: 0.4847\n",
      "Epoch 10 | Loss: 0.2342\n",
      "Epoch 11 | Loss: 0.1227\n",
      "Epoch 12 | Loss: 0.0775\n",
      "Epoch 13 | Loss: 0.0616\n",
      "Epoch 14 | Loss: 0.0644\n",
      "Epoch 15 | Loss: 0.0693\n",
      "Epoch 16 | Loss: 0.0649\n",
      "Epoch 17 | Loss: 0.0556\n",
      "Epoch 18 | Loss: 0.0476\n",
      "Epoch 19 | Loss: 0.0406\n",
      "Epoch 20 | Loss: 0.0320\n",
      "Epoch 21 | Loss: 0.0258\n",
      "Epoch 22 | Loss: 0.0275\n",
      "Epoch 23 | Loss: 0.0330\n",
      "Epoch 24 | Loss: 0.0314\n",
      "Epoch 25 | Loss: 0.0244\n",
      "Epoch 26 | Loss: 0.0194\n",
      "Epoch 27 | Loss: 0.0171\n",
      "Epoch 28 | Loss: 0.0149\n",
      "Epoch 29 | Loss: 0.0142\n",
      "Epoch 30 | Loss: 0.0148\n",
      "Epoch 31 | Loss: 0.0139\n",
      "Epoch 32 | Loss: 0.0116\n",
      "Epoch 33 | Loss: 0.0094\n",
      "Epoch 34 | Loss: 0.0085\n",
      "Epoch 35 | Loss: 0.0084\n",
      "Epoch 36 | Loss: 0.0081\n",
      "Epoch 37 | Loss: 0.0069\n",
      "Epoch 38 | Loss: 0.0053\n",
      "Epoch 39 | Loss: 0.0041\n",
      "Epoch 40 | Loss: 0.0042\n",
      "Epoch 41 | Loss: 0.0051\n",
      "Epoch 42 | Loss: 0.0052\n",
      "Epoch 43 | Loss: 0.0042\n",
      "Epoch 44 | Loss: 0.0027\n",
      "Epoch 45 | Loss: 0.0016\n",
      "Epoch 46 | Loss: 0.0017\n",
      "Epoch 47 | Loss: 0.0025\n",
      "Epoch 48 | Loss: 0.0030\n",
      "Epoch 49 | Loss: 0.0026\n",
      "Epoch 50 | Loss: 0.0017\n",
      "Epoch 51 | Loss: 0.0010\n",
      "Epoch 52 | Loss: 0.0008\n",
      "Epoch 53 | Loss: 0.0010\n",
      "Epoch 54 | Loss: 0.0013\n",
      "Epoch 55 | Loss: 0.0014\n",
      "Epoch 56 | Loss: 0.0013\n",
      "Epoch 57 | Loss: 0.0008\n",
      "Epoch 58 | Loss: 0.0004\n",
      "Epoch 59 | Loss: 0.0004\n",
      "Epoch 60 | Loss: 0.0005\n",
      "Epoch 61 | Loss: 0.0007\n",
      "Epoch 62 | Loss: 0.0007\n",
      "Epoch 63 | Loss: 0.0006\n",
      "Epoch 64 | Loss: 0.0004\n",
      "Epoch 65 | Loss: 0.0002\n",
      "Epoch 66 | Loss: 0.0002\n",
      "Epoch 67 | Loss: 0.0003\n",
      "Epoch 68 | Loss: 0.0003\n",
      "Epoch 69 | Loss: 0.0003\n",
      "Epoch 70 | Loss: 0.0002\n",
      "Epoch 71 | Loss: 0.0002\n",
      "Epoch 72 | Loss: 0.0001\n",
      "Epoch 73 | Loss: 0.0001\n",
      "Epoch 74 | Loss: 0.0001\n",
      "Epoch 75 | Loss: 0.0002\n",
      "Epoch 76 | Loss: 0.0002\n",
      "Epoch 77 | Loss: 0.0001\n",
      "Epoch 78 | Loss: 0.0001\n",
      "Epoch 79 | Loss: 0.0001\n",
      "Epoch 80 | Loss: 0.0001\n",
      "Epoch 81 | Loss: 0.0001\n",
      "Epoch 82 | Loss: 0.0001\n",
      "Epoch 83 | Loss: 0.0001\n",
      "Epoch 84 | Loss: 0.0000\n",
      "Epoch 85 | Loss: 0.0000\n",
      "Epoch 86 | Loss: 0.0000\n",
      "Epoch 87 | Loss: 0.0000\n",
      "Epoch 88 | Loss: 0.0000\n",
      "Epoch 89 | Loss: 0.0000\n",
      "Epoch 90 | Loss: 0.0000\n",
      "Epoch 91 | Loss: 0.0000\n",
      "Epoch 92 | Loss: 0.0000\n",
      "Epoch 93 | Loss: 0.0000\n",
      "Epoch 94 | Loss: 0.0000\n",
      "Epoch 95 | Loss: 0.0000\n",
      "Epoch 96 | Loss: 0.0000\n",
      "Epoch 97 | Loss: 0.0000\n",
      "Epoch 98 | Loss: 0.0000\n",
      "Epoch 99 | Loss: 0.0000\n",
      "Epoch 100 | Loss: 0.0000\n",
      "Epoch 101 | Loss: 0.0000\n",
      "Epoch 102 | Loss: 0.0000\n",
      "Epoch 103 | Loss: 0.0000\n",
      "Epoch 104 | Loss: 0.0000\n",
      "Epoch 105 | Loss: 0.0000\n",
      "Epoch 106 | Loss: 0.0000\n",
      "Epoch 107 | Loss: 0.0000\n",
      "Epoch 108 | Loss: 0.0000\n",
      "Epoch 109 | Loss: 0.0000\n",
      "Epoch 110 | Loss: 0.0000\n",
      "Epoch 111 | Loss: 0.0000\n",
      "Epoch 112 | Loss: 0.0000\n",
      "Epoch 113 | Loss: 0.0000\n",
      "Epoch 114 | Loss: 0.0000\n",
      "Epoch 115 | Loss: 0.0000\n",
      "Epoch 116 | Loss: 0.0000\n",
      "Epoch 117 | Loss: 0.0000\n",
      "Epoch 118 | Loss: 0.0000\n",
      "Epoch 119 | Loss: 0.0000\n",
      "Epoch 120 | Loss: 0.0000\n",
      "Epoch 121 | Loss: 0.0000\n",
      "Epoch 122 | Loss: 0.0000\n",
      "Epoch 123 | Loss: 0.0000\n",
      "Epoch 124 | Loss: 0.0000\n",
      "Epoch 125 | Loss: 0.0000\n",
      "Epoch 126 | Loss: 0.0000\n",
      "Epoch 127 | Loss: 0.0000\n",
      "Epoch 128 | Loss: 0.0000\n",
      "Epoch 129 | Loss: 0.0000\n",
      "Epoch 130 | Loss: 0.0000\n",
      "Epoch 131 | Loss: 0.0000\n",
      "Epoch 132 | Loss: 0.0000\n",
      "Epoch 133 | Loss: 0.0000\n",
      "Epoch 134 | Loss: 0.0000\n",
      "Epoch 135 | Loss: 0.0000\n",
      "Epoch 136 | Loss: 0.0000\n",
      "Epoch 137 | Loss: 0.0000\n",
      "Epoch 138 | Loss: 0.0000\n",
      "Epoch 139 | Loss: 0.0000\n",
      "Epoch 140 | Loss: 0.0000\n",
      "Epoch 141 | Loss: 0.0000\n",
      "Epoch 142 | Loss: 0.0000\n",
      "Epoch 143 | Loss: 0.0000\n",
      "Epoch 144 | Loss: 0.0000\n",
      "Epoch 145 | Loss: 0.0000\n",
      "Epoch 146 | Loss: 0.0000\n",
      "Epoch 147 | Loss: 0.0000\n",
      "Epoch 148 | Loss: 0.0001\n",
      "Epoch 149 | Loss: 0.0001\n",
      "Epoch 150 | Loss: 0.0000\n",
      "Epoch 151 | Loss: 0.0000\n",
      "Epoch 152 | Loss: 0.0000\n",
      "Epoch 153 | Loss: 0.0000\n",
      "Epoch 154 | Loss: 0.0000\n",
      "Epoch 155 | Loss: 0.0000\n",
      "Epoch 156 | Loss: 0.0000\n",
      "Epoch 157 | Loss: 0.0000\n",
      "Epoch 158 | Loss: 0.0000\n",
      "Epoch 159 | Loss: 0.0000\n",
      "Epoch 160 | Loss: 0.0001\n",
      "Epoch 161 | Loss: 0.0000\n",
      "Epoch 162 | Loss: 0.0000\n",
      "Epoch 163 | Loss: 0.0000\n",
      "Epoch 164 | Loss: 0.0000\n",
      "Epoch 165 | Loss: 0.0000\n",
      "Epoch 166 | Loss: 0.0000\n",
      "Epoch 167 | Loss: 0.0000\n",
      "Epoch 168 | Loss: 0.0000\n",
      "Epoch 169 | Loss: 0.0000\n",
      "Epoch 170 | Loss: 0.0000\n",
      "Epoch 171 | Loss: 0.0000\n",
      "Epoch 172 | Loss: 0.0000\n",
      "Epoch 173 | Loss: 0.0000\n",
      "Epoch 174 | Loss: 0.0000\n",
      "Epoch 175 | Loss: 0.0000\n",
      "Epoch 176 | Loss: 0.0000\n",
      "Epoch 177 | Loss: 0.0000\n",
      "Epoch 178 | Loss: 0.0000\n",
      "Epoch 179 | Loss: 0.0000\n",
      "Epoch 180 | Loss: 0.0000\n",
      "Epoch 181 | Loss: 0.0000\n",
      "Epoch 182 | Loss: 0.0000\n",
      "Epoch 183 | Loss: 0.0000\n",
      "Epoch 184 | Loss: 0.0000\n",
      "Epoch 185 | Loss: 0.0000\n",
      "Epoch 186 | Loss: 0.0000\n",
      "Epoch 187 | Loss: 0.0000\n",
      "Epoch 188 | Loss: 0.0000\n",
      "Epoch 189 | Loss: 0.0000\n",
      "Epoch 190 | Loss: 0.0000\n",
      "Epoch 191 | Loss: 0.0000\n",
      "Epoch 192 | Loss: 0.0000\n",
      "Epoch 193 | Loss: 0.0000\n",
      "Epoch 194 | Loss: 0.0000\n",
      "Epoch 195 | Loss: 0.0000\n",
      "Epoch 196 | Loss: 0.0000\n",
      "Epoch 197 | Loss: 0.0000\n",
      "Epoch 198 | Loss: 0.0000\n",
      "Epoch 199 | Loss: 0.0000\n",
      "Epoch 200 | Loss: 0.0000\n",
      "Epoch 201 | Loss: 0.0000\n",
      "Epoch 202 | Loss: 0.0000\n",
      "Epoch 203 | Loss: 0.0000\n",
      "Epoch 204 | Loss: 0.0000\n",
      "Epoch 205 | Loss: 0.0000\n",
      "Epoch 206 | Loss: 0.0000\n",
      "Epoch 207 | Loss: 0.0000\n",
      "Epoch 208 | Loss: 0.0000\n",
      "Epoch 209 | Loss: 0.0000\n",
      "Epoch 210 | Loss: 0.0000\n",
      "Epoch 211 | Loss: 0.0001\n",
      "Epoch 212 | Loss: 0.0001\n",
      "Epoch 213 | Loss: 0.0000\n",
      "Epoch 214 | Loss: 0.0001\n",
      "Epoch 215 | Loss: 0.0001\n",
      "Epoch 216 | Loss: 0.0001\n",
      "Epoch 217 | Loss: 0.0001\n",
      "Epoch 218 | Loss: 0.0000\n",
      "Epoch 219 | Loss: 0.0000\n",
      "Epoch 220 | Loss: 0.0000\n",
      "Epoch 221 | Loss: 0.0000\n",
      "Epoch 222 | Loss: 0.0000\n",
      "Epoch 223 | Loss: 0.0000\n",
      "Epoch 224 | Loss: 0.0000\n",
      "Epoch 225 | Loss: 0.0000\n",
      "Epoch 226 | Loss: 0.0000\n",
      "Epoch 227 | Loss: 0.0000\n",
      "Epoch 228 | Loss: 0.0000\n",
      "Epoch 229 | Loss: 0.0000\n",
      "Epoch 230 | Loss: 0.0000\n",
      "Epoch 231 | Loss: 0.0000\n",
      "Epoch 232 | Loss: 0.0000\n",
      "Epoch 233 | Loss: 0.0000\n",
      "Epoch 234 | Loss: 0.0000\n",
      "Epoch 235 | Loss: 0.0000\n",
      "Epoch 236 | Loss: 0.0000\n",
      "Epoch 237 | Loss: 0.0000\n",
      "Epoch 238 | Loss: 0.0000\n",
      "Epoch 239 | Loss: 0.0000\n",
      "Epoch 240 | Loss: 0.0000\n",
      "Epoch 241 | Loss: 0.0000\n",
      "Epoch 242 | Loss: 0.0000\n",
      "Epoch 243 | Loss: 0.0000\n",
      "Epoch 244 | Loss: 0.0000\n",
      "Epoch 245 | Loss: 0.0000\n",
      "Epoch 246 | Loss: 0.0000\n",
      "Epoch 247 | Loss: 0.0000\n",
      "Epoch 248 | Loss: 0.0000\n",
      "Epoch 249 | Loss: 0.0000\n",
      "Epoch 250 | Loss: 0.0000\n",
      "Epoch 251 | Loss: 0.0000\n",
      "Epoch 252 | Loss: 0.0000\n",
      "Epoch 253 | Loss: 0.0000\n",
      "Epoch 254 | Loss: 0.0000\n",
      "Epoch 255 | Loss: 0.0000\n",
      "Epoch 256 | Loss: 0.0000\n",
      "Epoch 257 | Loss: 0.0000\n",
      "Epoch 258 | Loss: 0.0000\n",
      "Epoch 259 | Loss: 0.0000\n",
      "Epoch 260 | Loss: 0.0000\n",
      "Epoch 261 | Loss: 0.0000\n",
      "Epoch 262 | Loss: 0.0000\n",
      "Epoch 263 | Loss: 0.0000\n",
      "Epoch 264 | Loss: 0.0000\n",
      "Epoch 265 | Loss: 0.0000\n",
      "Epoch 266 | Loss: 0.0000\n",
      "Epoch 267 | Loss: 0.0000\n",
      "Epoch 268 | Loss: 0.0000\n",
      "Epoch 269 | Loss: 0.0000\n",
      "Epoch 270 | Loss: 0.0000\n",
      "Epoch 271 | Loss: 0.0000\n",
      "Epoch 272 | Loss: 0.0000\n",
      "Epoch 273 | Loss: 0.0000\n",
      "Epoch 274 | Loss: 0.0000\n",
      "Epoch 275 | Loss: 0.0000\n",
      "Epoch 276 | Loss: 0.0001\n",
      "Epoch 277 | Loss: 0.0001\n",
      "Epoch 278 | Loss: 0.0001\n",
      "Epoch 279 | Loss: 0.0001\n",
      "Epoch 280 | Loss: 0.0001\n",
      "Epoch 281 | Loss: 0.0001\n",
      "Epoch 282 | Loss: 0.0001\n",
      "Epoch 283 | Loss: 0.0001\n",
      "Epoch 284 | Loss: 0.0001\n",
      "Epoch 285 | Loss: 0.0001\n",
      "Epoch 286 | Loss: 0.0001\n",
      "Epoch 287 | Loss: 0.0001\n",
      "Epoch 288 | Loss: 0.0001\n",
      "Epoch 289 | Loss: 0.0001\n",
      "Epoch 290 | Loss: 0.0001\n",
      "Epoch 291 | Loss: 0.0001\n",
      "Epoch 292 | Loss: 0.0001\n",
      "Epoch 293 | Loss: 0.0001\n",
      "Epoch 294 | Loss: 0.0001\n",
      "Epoch 295 | Loss: 0.0001\n",
      "Epoch 296 | Loss: 0.0001\n",
      "Epoch 297 | Loss: 0.0001\n",
      "Epoch 298 | Loss: 0.0000\n",
      "Epoch 299 | Loss: 0.0000\n",
      "Epoch 300 | Loss: 0.0000\n",
      "Epoch 301 | Loss: 0.0000\n",
      "Epoch 302 | Loss: 0.0000\n",
      "Epoch 303 | Loss: 0.0000\n",
      "Epoch 304 | Loss: 0.0000\n",
      "Epoch 305 | Loss: 0.0000\n",
      "Epoch 306 | Loss: 0.0000\n",
      "Epoch 307 | Loss: 0.0000\n",
      "Epoch 308 | Loss: 0.0000\n",
      "Epoch 309 | Loss: 0.0000\n",
      "Epoch 310 | Loss: 0.0000\n",
      "Epoch 311 | Loss: 0.0000\n",
      "Epoch 312 | Loss: 0.0000\n",
      "Epoch 313 | Loss: 0.0000\n",
      "Epoch 314 | Loss: 0.0000\n",
      "Epoch 315 | Loss: 0.0000\n",
      "Epoch 316 | Loss: 0.0000\n",
      "Epoch 317 | Loss: 0.0000\n",
      "Epoch 318 | Loss: 0.0000\n",
      "Epoch 319 | Loss: 0.0000\n",
      "Epoch 320 | Loss: 0.0000\n",
      "Epoch 321 | Loss: 0.0000\n",
      "Epoch 322 | Loss: 0.0000\n",
      "Epoch 323 | Loss: 0.0000\n",
      "Epoch 324 | Loss: 0.0000\n",
      "Epoch 325 | Loss: 0.0000\n",
      "Epoch 326 | Loss: 0.0000\n",
      "Epoch 327 | Loss: 0.0000\n",
      "Epoch 328 | Loss: 0.0000\n",
      "Epoch 329 | Loss: 0.0000\n",
      "Epoch 330 | Loss: 0.0000\n",
      "Epoch 331 | Loss: 0.0000\n",
      "Epoch 332 | Loss: 0.0000\n",
      "Epoch 333 | Loss: 0.0000\n",
      "Epoch 334 | Loss: 0.0000\n",
      "Epoch 335 | Loss: 0.0000\n",
      "Epoch 336 | Loss: 0.0000\n",
      "Epoch 337 | Loss: 0.0000\n",
      "Epoch 338 | Loss: 0.0000\n",
      "Epoch 339 | Loss: 0.0000\n",
      "Epoch 340 | Loss: 0.0000\n",
      "Epoch 341 | Loss: 0.0000\n",
      "Epoch 342 | Loss: 0.0000\n",
      "Epoch 343 | Loss: 0.0000\n",
      "Epoch 344 | Loss: 0.0000\n",
      "Epoch 345 | Loss: 0.0000\n",
      "Epoch 346 | Loss: 0.0000\n",
      "Epoch 347 | Loss: 0.0001\n",
      "Epoch 348 | Loss: 0.0001\n",
      "Epoch 349 | Loss: 0.0002\n",
      "Epoch 350 | Loss: 0.0004\n",
      "Epoch 351 | Loss: 0.0006\n",
      "Epoch 352 | Loss: 0.0008\n",
      "Epoch 353 | Loss: 0.0009\n",
      "Epoch 354 | Loss: 0.0008\n",
      "Epoch 355 | Loss: 0.0005\n",
      "Epoch 356 | Loss: 0.0003\n",
      "Epoch 357 | Loss: 0.0002\n",
      "Epoch 358 | Loss: 0.0003\n",
      "Epoch 359 | Loss: 0.0004\n",
      "Epoch 360 | Loss: 0.0003\n",
      "Epoch 361 | Loss: 0.0002\n",
      "Epoch 362 | Loss: 0.0001\n",
      "Epoch 363 | Loss: 0.0001\n",
      "Epoch 364 | Loss: 0.0002\n",
      "Epoch 365 | Loss: 0.0002\n",
      "Epoch 366 | Loss: 0.0001\n",
      "Epoch 367 | Loss: 0.0000\n",
      "Epoch 368 | Loss: 0.0001\n",
      "Epoch 369 | Loss: 0.0001\n",
      "Epoch 370 | Loss: 0.0001\n",
      "Epoch 371 | Loss: 0.0000\n",
      "Epoch 372 | Loss: 0.0000\n",
      "Epoch 373 | Loss: 0.0001\n",
      "Epoch 374 | Loss: 0.0001\n",
      "Epoch 375 | Loss: 0.0001\n",
      "Epoch 376 | Loss: 0.0000\n",
      "Epoch 377 | Loss: 0.0000\n",
      "Epoch 378 | Loss: 0.0000\n",
      "Epoch 379 | Loss: 0.0000\n",
      "Epoch 380 | Loss: 0.0000\n",
      "Epoch 381 | Loss: 0.0000\n",
      "Epoch 382 | Loss: 0.0000\n",
      "Epoch 383 | Loss: 0.0000\n",
      "Epoch 384 | Loss: 0.0000\n",
      "Epoch 385 | Loss: 0.0000\n",
      "Epoch 386 | Loss: 0.0000\n",
      "Epoch 387 | Loss: 0.0000\n",
      "Epoch 388 | Loss: 0.0000\n",
      "Epoch 389 | Loss: 0.0000\n",
      "Epoch 390 | Loss: 0.0000\n",
      "Epoch 391 | Loss: 0.0000\n",
      "Epoch 392 | Loss: 0.0000\n",
      "Epoch 393 | Loss: 0.0000\n",
      "Epoch 394 | Loss: 0.0000\n",
      "Epoch 395 | Loss: 0.0000\n",
      "Epoch 396 | Loss: 0.0000\n",
      "Epoch 397 | Loss: 0.0000\n",
      "Epoch 398 | Loss: 0.0000\n",
      "Epoch 399 | Loss: 0.0000\n",
      "Epoch 400 | Loss: 0.0000\n",
      "Epoch 401 | Loss: 0.0000\n",
      "Epoch 402 | Loss: 0.0000\n",
      "Epoch 403 | Loss: 0.0000\n",
      "Epoch 404 | Loss: 0.0000\n",
      "Epoch 405 | Loss: 0.0000\n",
      "Epoch 406 | Loss: 0.0000\n",
      "Epoch 407 | Loss: 0.0000\n",
      "Epoch 408 | Loss: 0.0000\n",
      "Epoch 409 | Loss: 0.0000\n",
      "Epoch 410 | Loss: 0.0000\n",
      "Epoch 411 | Loss: 0.0000\n",
      "Epoch 412 | Loss: 0.0000\n",
      "Epoch 413 | Loss: 0.0000\n",
      "Epoch 414 | Loss: 0.0000\n",
      "Epoch 415 | Loss: 0.0000\n",
      "Epoch 416 | Loss: 0.0000\n",
      "Epoch 417 | Loss: 0.0000\n",
      "Epoch 418 | Loss: 0.0000\n",
      "Epoch 419 | Loss: 0.0000\n",
      "Epoch 420 | Loss: 0.0000\n",
      "Epoch 421 | Loss: 0.0000\n",
      "Epoch 422 | Loss: 0.0000\n",
      "Epoch 423 | Loss: 0.0000\n",
      "Epoch 424 | Loss: 0.0000\n",
      "Epoch 425 | Loss: 0.0000\n",
      "Epoch 426 | Loss: 0.0000\n",
      "Epoch 427 | Loss: 0.0000\n",
      "Epoch 428 | Loss: 0.0000\n",
      "Epoch 429 | Loss: 0.0000\n",
      "Epoch 430 | Loss: 0.0000\n",
      "Epoch 431 | Loss: 0.0000\n",
      "Epoch 432 | Loss: 0.0000\n",
      "Epoch 433 | Loss: 0.0000\n",
      "Epoch 434 | Loss: 0.0000\n",
      "Epoch 435 | Loss: 0.0000\n",
      "Epoch 436 | Loss: 0.0000\n",
      "Epoch 437 | Loss: 0.0000\n",
      "Epoch 438 | Loss: 0.0000\n",
      "Epoch 439 | Loss: 0.0000\n",
      "Epoch 440 | Loss: 0.0000\n",
      "Epoch 441 | Loss: 0.0000\n",
      "Epoch 442 | Loss: 0.0000\n",
      "Epoch 443 | Loss: 0.0000\n",
      "Epoch 444 | Loss: 0.0000\n",
      "Epoch 445 | Loss: 0.0000\n",
      "Epoch 446 | Loss: 0.0000\n",
      "Epoch 447 | Loss: 0.0000\n",
      "Epoch 448 | Loss: 0.0000\n",
      "Epoch 449 | Loss: 0.0000\n",
      "Epoch 450 | Loss: 0.0000\n",
      "Epoch 451 | Loss: 0.0000\n",
      "Epoch 452 | Loss: 0.0000\n",
      "Epoch 453 | Loss: 0.0000\n",
      "Epoch 454 | Loss: 0.0000\n",
      "Epoch 455 | Loss: 0.0000\n",
      "Epoch 456 | Loss: 0.0000\n",
      "Epoch 457 | Loss: 0.0000\n",
      "Epoch 458 | Loss: 0.0000\n",
      "Epoch 459 | Loss: 0.0000\n",
      "Epoch 460 | Loss: 0.0001\n",
      "Epoch 461 | Loss: 0.0001\n",
      "Epoch 462 | Loss: 0.0001\n",
      "Epoch 463 | Loss: 0.0002\n",
      "Epoch 464 | Loss: 0.0002\n",
      "Epoch 465 | Loss: 0.0003\n",
      "Epoch 466 | Loss: 0.0003\n",
      "Epoch 467 | Loss: 0.0003\n",
      "Epoch 468 | Loss: 0.0003\n",
      "Epoch 469 | Loss: 0.0002\n",
      "Epoch 470 | Loss: 0.0002\n",
      "Epoch 471 | Loss: 0.0001\n",
      "Epoch 472 | Loss: 0.0001\n",
      "Epoch 473 | Loss: 0.0001\n",
      "Epoch 474 | Loss: 0.0001\n",
      "Epoch 475 | Loss: 0.0001\n",
      "Epoch 476 | Loss: 0.0001\n",
      "Epoch 477 | Loss: 0.0001\n",
      "Epoch 478 | Loss: 0.0000\n",
      "Epoch 479 | Loss: 0.0000\n",
      "Epoch 480 | Loss: 0.0000\n",
      "Epoch 481 | Loss: 0.0000\n",
      "Epoch 482 | Loss: 0.0000\n",
      "Epoch 483 | Loss: 0.0001\n",
      "Epoch 484 | Loss: 0.0001\n",
      "Epoch 485 | Loss: 0.0000\n",
      "Epoch 486 | Loss: 0.0000\n",
      "Epoch 487 | Loss: 0.0000\n",
      "Epoch 488 | Loss: 0.0000\n",
      "Epoch 489 | Loss: 0.0000\n",
      "Epoch 490 | Loss: 0.0000\n",
      "Epoch 491 | Loss: 0.0000\n",
      "Epoch 492 | Loss: 0.0000\n",
      "Epoch 493 | Loss: 0.0000\n",
      "Epoch 494 | Loss: 0.0000\n",
      "Epoch 495 | Loss: 0.0000\n",
      "Epoch 496 | Loss: 0.0000\n",
      "Epoch 497 | Loss: 0.0000\n",
      "Epoch 498 | Loss: 0.0000\n",
      "Epoch 499 | Loss: 0.0000\n",
      "Epoch 500 | Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from dataset import CollegeFacilitiesDataset\n",
    "from model import SimpleDetector\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    # 'chair', 'bench', 'desk', 'table', 'sofa', 'podium', 'cupboard', 'whiteboard', 'blackboard', 'notice board',\n",
    "    # 'projector', 'screen', 'computer', 'monitor', 'keyboard', 'mouse', 'CPU', 'smart board', 'chalk', 'duster',\n",
    "    # 'lab table', 'test tube', 'beaker', 'microscope', 'chemical bottle', 'lab coat', 'fire extinguisher', 'fume hood',\n",
    "    # 'fan', 'AC', 'switchboard', 'tube light', 'window', 'curtain', 'door', 'clock', 'dustbin',\n",
    "    # 'wash basin', 'toilet seat', 'urinal', 'mirror', 'soap dispenser', 'hand dryer', 'water cooler', 'bucket', 'mug',\n",
    "    # 'bookshelf', 'book', 'newspaper stand', 'magazine rack',\n",
    "    # 'CCTV camera', 'security guard', 'fire alarm', 'student', 'teacher'\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "  \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "  \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "  \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\",\n",
    "  \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "  \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\",\n",
    "  \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "  \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\",\n",
    "  \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "  \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "  \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "MAX_OBJECTS = 20  \n",
    "\n",
    "model = SimpleDetector(num_classes=NUM_CLASSES, max_objects=MAX_OBJECTS).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "bbox_loss_fn = torch.nn.MSELoss()\n",
    "cls_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = CollegeFacilitiesDataset(\n",
    "   annotations_file=\"data/train/coco2017/annotations/labels.json\",\n",
    "    image_dir=\"data/train/coco2017/train2017\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, all_bboxes, all_class_ids = [], [], []\n",
    "\n",
    "    for image, bboxes, class_ids in batch:\n",
    "        images.append(image)\n",
    "\n",
    "        n = bboxes.shape[0]\n",
    "        if n < MAX_OBJECTS:\n",
    "            bboxes = torch.cat([bboxes, torch.zeros((MAX_OBJECTS - n, 4))], dim=0)\n",
    "            class_ids = torch.cat([class_ids, torch.zeros(MAX_OBJECTS - n, dtype=torch.long)], dim=0)\n",
    "        elif n > MAX_OBJECTS:\n",
    "            bboxes = bboxes[:MAX_OBJECTS]\n",
    "            class_ids = class_ids[:MAX_OBJECTS]\n",
    "\n",
    "        all_bboxes.append(bboxes)\n",
    "        all_class_ids.append(class_ids)\n",
    "\n",
    "    return torch.stack(images), torch.stack(all_bboxes), torch.stack(all_class_ids)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, bboxes, class_ids in train_loader:\n",
    "        images = images.to(device)\n",
    "        bboxes = bboxes.to(device)\n",
    "        class_ids = class_ids.to(device)\n",
    "\n",
    "        preds = model(images)\n",
    "\n",
    "        pred_bboxes = preds[..., :4]\n",
    "        pred_class_logits = preds[..., 4:]\n",
    "\n",
    "        loss_bbox = bbox_loss_fn(pred_bboxes, bboxes)\n",
    "        loss_cls = cls_loss_fn(pred_class_logits.view(-1, NUM_CLASSES), class_ids.view(-1))\n",
    "\n",
    "        loss = loss_bbox + loss_cls\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"simple_detector.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d05b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw\n",
    "from model import SimpleDetector\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    # 'chair', 'bench', 'desk', 'table', 'sofa', 'podium', 'cupboard', 'whiteboard', 'blackboard', 'notice board',\n",
    "    # 'projector', 'screen', 'computer', 'monitor', 'keyboard', 'mouse', 'CPU', 'smart board', 'chalk', 'duster',\n",
    "    # 'lab table', 'test tube', 'beaker', 'microscope', 'chemical bottle', 'lab coat', 'fire extinguisher', 'fume hood',\n",
    "    # 'fan', 'AC', 'switchboard', 'tube light', 'window', 'curtain', 'door', 'clock', 'dustbin',\n",
    "    # 'wash basin', 'toilet seat', 'urinal', 'mirror', 'soap dispenser', 'hand dryer', 'water cooler', 'bucket', 'mug',\n",
    "    # 'bookshelf', 'book', 'newspaper stand', 'magazine rack',\n",
    "    # 'CCTV camera', 'security guard', 'fire alarm', 'student', 'teacher'\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "  \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "  \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "  \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\",\n",
    "  \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "  \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\",\n",
    "  \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "  \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\",\n",
    "  \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "  \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "  \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "MAX_OBJECTS = 20 \n",
    "\n",
    "model = SimpleDetector(num_classes=NUM_CLASSES, max_objects=MAX_OBJECTS)\n",
    "model.load_state_dict(torch.load(\"simple_detector.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# def denormalize_bbox(box, w, h):\n",
    "#     x_c, y_c, bw, bh = box.tolist()\n",
    "\n",
    "#     x1 = max(0, (x_c - bw / 2) * w)\n",
    "#     y1 = max(0, (y_c - bh / 2) * h)\n",
    "#     x2 = min(w, (x_c + bw / 2) * w)\n",
    "#     y2 = min(h, (y_c + bh / 2) * h)\n",
    "\n",
    "#     # Ensure y2 >= y1 and x2 >= x1\n",
    "#     x1, x2 = sorted([x1, x2])\n",
    "#     y1, y2 = sorted([y1, y2])\n",
    "\n",
    "#     return [x1, y1, x2, y2]\n",
    "def denormalize_bbox(box, img_w, img_h):\n",
    "    x_c, y_c, w, h = box.tolist()\n",
    "    x1 = (x_c - w/2) * img_w\n",
    "    y1 = (y_c - h/2) * img_h\n",
    "    x2 = (x_c + w/2) * img_w\n",
    "    y2 = (y_c + h/2) * img_h\n",
    "\n",
    "    # Ensure box coordinates are valid\n",
    "    x1, x2 = sorted([x1, x2])\n",
    "    y1, y2 = sorted([y1, y2])\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "\n",
    "def predict(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    orig_w, orig_h = image.size\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)[0]  # [MAX_OBJECTS, 4+NUM_CLASSES]\n",
    "        bboxes = output[:, :4]\n",
    "        class_logits = output[:, 4:]\n",
    "        class_preds = class_logits.argmax(dim=1)\n",
    "        scores = class_logits.softmax(dim=1).max(dim=1)[0]\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for i in range(MAX_OBJECTS):\n",
    "        if scores[i] < 0.5:\n",
    "            continue\n",
    "        label = CLASS_NAMES[class_preds[i]]\n",
    "        box = denormalize_bbox(bboxes[i].cpu(), orig_w, orig_h)\n",
    "        draw.rectangle(box, outline=\"red\", width=2)\n",
    "        draw.text((box[0], box[1]), label, fill=\"yellow\")\n",
    "\n",
    "    image.show()\n",
    "\n",
    "# Example usage\n",
    "predict(\"000000000030.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3343fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15896921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf538da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c8e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54e4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
